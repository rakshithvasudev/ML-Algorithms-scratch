{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree with CART using Information gain, Gini Impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the core idea between gini impurity and gini co-efficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gini impurity is a measure of misclassification, which applies in a multiclass classifier context.\n",
    "* Gini coefficient applies to binary classification and requires a classifier that can in some way rank examples according to the likelihood of being in a positive class."
   ]
  },
  {
   "attachments": {
    "Image3.gif": {
     "image/gif": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image3.gif](attachment:Image3.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Toy dataset.\n",
    "# Format: each row is an example.\n",
    "# The last column is the label.\n",
    "# The first two columns are features.\n",
    "# Feel free to play with it by adding more features & examples.\n",
    "# Interesting note: I've written this so the 2nd and 5th examples\n",
    "# have the same features, but different labels - so we can see how the\n",
    "# tree handles this case.\n",
    "training_data = [\n",
    "    ['Green', 3, 'Apple'],\n",
    "    ['Yellow', 3, 'Apple'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Yellow', 3, 'Lemon'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Column labels.\n",
    "# These are used only to print the tree.\n",
    "header = [\"color\", \"diameter\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['color', 'diameter', 'label']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Green', 3, 'Apple'],\n",
       " ['Yellow', 3, 'Apple'],\n",
       " ['Red', 1, 'Grape'],\n",
       " ['Red', 1, 'Grape'],\n",
       " ['Yellow', 3, 'Lemon']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(header)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_vals(rows, col):\n",
    "    \"\"\"Find the unique values for a column in a given dataset.\n",
    "       returns a set of unique values in that column - feature. \n",
    "    \"\"\"\n",
    "    return set([row_element[col] for row_element in rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Green', 'Red', 'Yellow'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the unique entires in the required cols\n",
    "unique_vals(training_data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_vals(training_data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(rows):\n",
    "    \"\"\" Counts the number of observations that belong to the final target class. \n",
    "        This function assumes the target label is the last column always. \"\"\"\n",
    "    \n",
    "    # class : observation counts\n",
    "    counts = {}\n",
    "    \n",
    "    # for every row check if the element is present & update accordingly.\n",
    "    for row_element in rows:\n",
    "        if row_element[-1] not in counts:\n",
    "            counts[row_element[-1]] = 0\n",
    "        counts[row_element[-1]]+=1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple': 2, 'Grape': 2, 'Lemon': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_numeric(value):\n",
    "    \"\"\"checks if an entry is a number.\"\"\"\n",
    "    return isinstance(value, int) or isinstance(value, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Question:\n",
    "    \"\"\"A Question is used to partition the dataset.\n",
    "\n",
    "    This class supports to ask questions on the dataset.\n",
    "    match() checks if the dataset specified  meets the required condition.\n",
    "    The condition is usually to check if the datapoint > number in the case of a numerical,\n",
    "    or equals in case of a string.\n",
    "    repr() makes the question more understandable - readable.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "    \n",
    "    def match(self, example):\n",
    "        \"\"\"\n",
    "        example: Sample datapoint to check on.\n",
    "        \"\"\"\n",
    "        val = example[self.column]\n",
    "        if is_numeric(val):\n",
    "            return val >= self.value\n",
    "        return val == self.value\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # This is just a helper method to print\n",
    "        # the question in a readable format.\n",
    "        condition = '=='\n",
    "        \n",
    "        if is_numeric(self.value):\n",
    "            condition = '>='\n",
    "        \n",
    "        return \"Is %s %s %s?\" % (\n",
    "            header[self.column],condition,str(self.value))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = Question(0,'Red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Question(0,'Yellow').match(training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition(rows, question):\n",
    "    \"\"\"Partitions a dataset.\n",
    "\n",
    "    For each row in the dataset, check if it matches the question. If\n",
    "    so, add it to 'true rows', otherwise, add it to 'false rows'.\n",
    "    \"\"\"\n",
    "    true_rows, false_rows = [], []\n",
    "    for row in rows:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_rows, false_rows = partition(training_data, Question(0, 'Red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Green', 3, 'Apple'], ['Yellow', 3, 'Apple'], ['Yellow', 3, 'Lemon']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Red', 1, 'Grape'], ['Red', 1, 'Grape']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Gini impurity at a node is the is the chance a randomly selected data point and a randomly selected target label in the dataset are incorrect match - misclassification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(rows):\n",
    "    \"\"\"Calculate the Gini Impurity for a list of rows.\n",
    "\n",
    "    There are a few different ways to do this, I thought this one was\n",
    "    the most concise. See:\n",
    "    https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
    "    \"\"\"\n",
    "    counts = class_counts(rows)    \n",
    "    impurity = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "        impurity -= prob_of_lbl**2\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the sample gini impurity \n",
    "gini([['Apple'],\n",
    "      ['Apple'],\n",
    "      ['fruit'],\n",
    "      ['Yellow']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6399999999999999"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def info_gain(left, right, current_uncertainty):\n",
    "    \"\"\"Information Gain.\n",
    "\n",
    "    The uncertainty of the starting node, minus the weighted impurity of\n",
    "    two child nodes.\n",
    "    \"\"\"\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_uncertainty - (p*gini(left)+ (1-p)*gini(right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much information do we gain by partioning on 'Green'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_uncertainty = gini(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1399999999999999"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_rows, false_rows = partition(training_data, Question(0, 'Green'))\n",
    "info_gain(true_rows, false_rows, current_uncertainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much information do we gain by partioning on 'Red'?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37333333333333324"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_rows, false_rows = partition(training_data, Question(0, 'Red'))\n",
    "info_gain(true_rows, false_rows, current_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Red', 1, 'Grape'], ['Red', 1, 'Grape']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Green', 3, 'Apple'], ['Yellow', 3, 'Apple'], ['Yellow', 3, 'Lemon']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(true_rows)\n",
    "false_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best split - such that we ask the right question is the challenge, as we can see, it must be automated to ask the right questions and make a splitting decision accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(rows):\n",
    "    \"\"\"\n",
    "    Iteratively search for the best feature and makes a split accordingly. \n",
    "    Returns the best information gain, best question.\n",
    "    \"\"\"\n",
    "    # set an arbitrary lower value to the best information gain. \n",
    "    best_ig = 0\n",
    "    \n",
    "    # keep a track of the best question\n",
    "    best_question = None\n",
    "    \n",
    "    # track all the features except the last feature of the row which actually is the target label.\n",
    "    n_features = len(rows[0])-1\n",
    "    \n",
    "    # compute the current uncertainity\n",
    "    current_uncertainty = gini(rows)\n",
    "    \n",
    "    # for feature index ask the best questions \n",
    "    for feature_idx in range(n_features):\n",
    "        # get the actual feature in all the features\n",
    "        for feature_value in unique_vals(rows, feature_idx):\n",
    "            \n",
    "            # ask the question based on the feature index and the feature value that\n",
    "            # is due to the current iteration.\n",
    "            current_question = Question(feature_idx,feature_value)\n",
    "            \n",
    "            # seperated rows based on the current question\n",
    "            true_rows, false_rows = partition(rows, current_question)\n",
    "            \n",
    "            # if there are no partitions then skip\n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "            \n",
    "            # get the current information gain\n",
    "            current_gain = info_gain(true_rows, false_rows, current_uncertainty)\n",
    "            \n",
    "            # assign the gains accordingly\n",
    "            if current_gain > best_ig:\n",
    "                best_ig = current_gain\n",
    "                best_question = current_question\n",
    "                \n",
    "    return best_ig, best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37333333333333324, Is color == Red?)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    \"\"\"A Leaf node classifies data.\n",
    "\n",
    "    This contains a dictionary of class (e.g., \"Apple\") -> number of times\n",
    "    it appears in the rows from the training data that reach this leaf.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rows):\n",
    "        self.predictions = class_counts(rows)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"%s\"%(self.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    \"\"\"A Decision Node asks a question.\n",
    "\n",
    "    This holds a reference to the question, and to the two child nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, question, true_branch, false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(rows):\n",
    "    \"\"\" Recursively Builds the tree.\n",
    "\n",
    "     Start by checking for the base case which is - (no further information gain).\n",
    "    \"\"\"\n",
    "\n",
    "    # Try partitioing the dataset on each of the unique attribute,\n",
    "    # calculate the information gain,\n",
    "    # and return the question that produces the highest gain.\n",
    "    gain, question = find_best_split(rows)\n",
    "    \n",
    "    print(\"-----------\")\n",
    "    print(question)\n",
    "    print(gain)\n",
    "    \n",
    "    # Base case: no further info gain\n",
    "    # Since we can ask no further questions,\n",
    "    # we'll return a leaf.\n",
    "    if gain == 0:\n",
    "        return Leaf(rows)\n",
    "\n",
    "    # If we reach here, we have found a useful feature / value\n",
    "    # to partition on.\n",
    "    true_rows, false_rows = partition(rows, question)\n",
    "    print(\"True %s \" %(true_rows))\n",
    "    print(\"False %s \" %(false_rows))\n",
    "    \n",
    "    # Recursively build the true branch.\n",
    "    true_branch = build_tree(true_rows)\n",
    "\n",
    "    # Recursively build the false branch.\n",
    "    false_branch = build_tree(false_rows)\n",
    "\n",
    "    # Return a Question node.\n",
    "    # This records the best feature / value to ask at this point,\n",
    "    # as well as the branches to follow\n",
    "    # depending on the answer.\n",
    "    return Decision_Node(question, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Is color == Red?\n",
      "0.37333333333333324\n",
      "True [['Red', 1, 'Grape'], ['Red', 1, 'Grape']] \n",
      "False [['Green', 3, 'Apple'], ['Yellow', 3, 'Apple'], ['Yellow', 3, 'Lemon']] \n",
      "-----------\n",
      "None\n",
      "0\n",
      "-----------\n",
      "Is color == Yellow?\n",
      "0.11111111111111116\n",
      "True [['Yellow', 3, 'Apple'], ['Yellow', 3, 'Lemon']] \n",
      "False [['Green', 3, 'Apple']] \n",
      "-----------\n",
      "None\n",
      "0\n",
      "-----------\n",
      "None\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "tree = build_tree(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=\"\"):\n",
    "    \"\"\" Just another tree printing function.\n",
    "    \"\"\"\n",
    "\n",
    "    # Base case: we've reached a leaf\n",
    "    if isinstance(node, Leaf):\n",
    "        print (spacing + \"Predict\", node.predictions)\n",
    "        return\n",
    "\n",
    "    # Print the question at this node\n",
    "    print (spacing + str(node.question))\n",
    "\n",
    "    # Call this function recursively on the true branch\n",
    "    print (spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "\n",
    "    # Call this function recursively on the false branch\n",
    "    print (spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is color == Red?\n",
      "--> True:\n",
      "  Predict {'Grape': 2}\n",
      "--> False:\n",
      "  Is color == Yellow?\n",
      "  --> True:\n",
      "    Predict {'Apple': 1, 'Lemon': 1}\n",
      "  --> False:\n",
      "    Predict {'Apple': 1}\n"
     ]
    }
   ],
   "source": [
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
