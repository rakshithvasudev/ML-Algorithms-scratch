# Decision Tree
Building a Decision Tree from scratch. Uses Gini Impurity as a measure.

Gini impurity is a measure of misclassification, which applies in a multiclass classifier context.

Gini impurity at a node is the is the chance a randomly selected data point and a randomly selected target label in the dataset are incorrect match - misclassification.


Gini coefficient applies to binary classification and requires a classifier that can in some way rank examples according to the likelihood of being in a positive class.


### Decision Tree using Gini impurity and Information Gain
<img src="https://github.com/rakshithvasudev/ML-Algorithms-scratch/blob/master/Decision%20Tree/images/Image3.gif"/>

### Gini impurity
<img src="https://github.com/rakshithvasudev/ML-Algorithms-scratch/blob/master/Decision%20Tree/images/gini.svg"/>

### Info gain
<img src=https://github.com/rakshithvasudev/ML-Algorithms-scratch/blob/master/Decision%20Tree/images/info%20gain.svg/>




# Acknowledgements
https://techdevguide.withgoogle.com/resources/ml-recipes-with-josh-gordon/#!
